import streamlit as st
import feedparser
import datetime
import os

# --- Page Configuration ---
# This should be the first Streamlit command in your script.
st.set_page_config(
    page_title="ì…œë¡ ì•„í‹°í´ í”¼ë“œ",
    page_icon="ğŸ“°",  # You can use an emoji or a URL to a .png file
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- Constants ---
# Assumes the RSS file is in the same directory as this script.
# When deploying to Streamlit Cloud, ensure this file is in your GitHub repo.
RSS_FILE_PATH = "neosherlock_feed_final.xml"

# --- Helper Functions ---
def load_feed(file_path):
    """Loads and parses the RSS feed from a local file."""
    if not os.path.exists(file_path):
        st.error(f"ğŸš¨ RSS íŒŒì¼({file_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    try:
        feed = feedparser.parse(file_path)
        # Check if parsing was successful (bozo bit is 0 for success)
        if feed.bozo:
            st.warning(f"âš ï¸ RSS í”¼ë“œ íŒŒì‹± ì¤‘ ì¼ë¶€ ë¬¸ì œê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤: {feed.bozo_exception}")
            # Continue processing even if there are non-critical parsing issues
        return feed
    except Exception as e:
        st.error(f"ğŸš¨ RSS íŒŒì¼ì„ ì½ê±°ë‚˜ íŒŒì‹±í•˜ëŠ” ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# --- Main Application UI ---
st.title("ğŸ“° ì…œë¡ ì•„í‹°í´ í”¼ë“œ")
st.caption(f"'{RSS_FILE_PATH}' íŒŒì¼ì—ì„œ ê¸°ì‚¬ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.")
st.markdown("---")

feed_data = load_feed(RSS_FILE_PATH)

if feed_data:
    if feed_data.entries:
        # Sort entries by publication date (descending - newest first)
        # feedparser converts dates to UTC time.struct_time in 'published_parsed'
        sorted_entries = sorted(
            feed_data.entries,
            key=lambda entry: entry.published_parsed if hasattr(entry, 'published_parsed') else (0,0,0,0,0,0,0,0,0), # fallback for missing date
            reverse=True
        )
        
        for entry in sorted_entries:
            with st.container():
                # Title as a clickable link, styled minimally
                if hasattr(entry, 'title') and hasattr(entry, 'link'):
                    st.markdown(
                        f"""
                        <a href="{entry.link}" target="_blank" style="text-decoration: none; color: inherit;">
                            <h3>{entry.title}</h3>
                        </a>
                        """,
                        unsafe_allow_html=True
                    )
                elif hasattr(entry, 'title'):
                    st.markdown(f"<h3>{entry.title}</h3>", unsafe_allow_html=True)


                # Metadata: Author and Publication Date
                meta_info_parts = []
                if hasattr(entry, 'author') and entry.author:
                    meta_info_parts.append(f"ğŸ‘¤ {entry.author}")

                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    try:
                        # feedparser stores 'published_parsed' as a UTC time.struct_time
                        utc_dt = datetime.datetime(*entry.published_parsed[:6], tzinfo=datetime.timezone.utc)
                        kst_tz = datetime.timezone(datetime.timedelta(hours=9))
                        kst_dt = utc_dt.astimezone(kst_tz)
                        meta_info_parts.append(f"ğŸ“… {kst_dt.strftime('%Yë…„ %mì›” %dì¼ %H:%M KST')}")
                    except Exception: # Fallback for any parsing/conversion error
                        if hasattr(entry, 'published'):
                             meta_info_parts.append(f"ğŸ“… {entry.published}")
                elif hasattr(entry, 'published') and entry.published: # Fallback if 'published_parsed' is missing
                    meta_info_parts.append(f"ğŸ“… {entry.published}")

                if meta_info_parts:
                    st.caption("  Â·  ".join(meta_info_parts))

                # Summary/Description
                if hasattr(entry, 'summary') and entry.summary:
                    with st.expander("ìš”ì•½ ë³´ê¸°", expanded=False): # Start collapsed
                        st.markdown(entry.summary, unsafe_allow_html=True) # Allow HTML if summary contains it
                
                st.markdown("---") # Visual separator between articles
    elif feed_data.bozo: # Feed was parsed but might have issues, and no entries
         st.warning("í”¼ë“œë¥¼ íŒŒì‹±í–ˆìœ¼ë‚˜, í‘œì‹œí•  ê²Œì‹œê¸€ì´ ì—†ê±°ë‚˜ í”¼ë“œ ë°ì´í„°ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else: # Feed object exists but no entries (and not bozo)
        st.info("â„¹ï¸ í”¼ë“œì— í‘œì‹œí•  ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤. RSS íŒŒì¼ì´ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
# else: load_feed function already displayed an error if feed_data is None

# Minimal footer (optional)
st.markdown("---")
st.markdown("<p style='text-align: center; color: grey; font-size: small;'>Neosherlock Article Feed | Powered by Streamlit</p>", unsafe_allow_html=True)